#!/usr/bin/env python3
"""
Script de Export de Dados CrÃ­ticos
Exporta dados essenciais para arquivo JSON como backup adicional
"""

import sys
import os
import sqlite3
import json
import logging
from datetime import datetime
from pathlib import Path

# Adiciona o diretÃ³rio raiz ao path
root_dir = os.path.join(os.path.dirname(__file__), '..')
sys.path.append(root_dir)
sys.path.append(os.path.join(root_dir, 'src'))

# Tenta importar config, se falhar usa caminho padrÃ£o
try:
    from src.sentinela.core.config import DATABASE_FILE
except ImportError:
    DATABASE_FILE = "data/database/sentinela.db"

# ConfiguraÃ§Ã£o de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(levelname)s] - %(message)s'
)

logger = logging.getLogger(__name__)

class CriticalDataExporter:
    def __init__(self, database_path: str):
        self.database_path = database_path
        self.export_dir = Path('backups/critical_data')
        self.export_dir.mkdir(parents=True, exist_ok=True)

    def get_db_connection(self):
        """Cria conexÃ£o com o banco de dados"""
        conn = sqlite3.connect(self.database_path)
        conn.row_factory = sqlite3.Row
        return conn

    def export_users_critical_data(self) -> list:
        """Exporta dados crÃ­ticos dos usuÃ¡rios (CPF â†” Telegram ID)"""
        users_data = []

        try:
            with self.get_db_connection() as conn:
                cursor = conn.execute("""
                    SELECT
                        user_id,
                        username,
                        cpf,
                        client_name,
                        service_name,
                        service_status,
                        is_active,
                        created_at,
                        last_verification
                    FROM users
                    WHERE user_id IS NOT NULL
                    ORDER BY user_id
                """)

                for row in cursor.fetchall():
                    users_data.append({
                        'user_id': row['user_id'],
                        'username': row['username'],
                        'cpf': row['cpf'],
                        'client_name': row['client_name'],
                        'service_name': row['service_name'],
                        'service_status': row['service_status'],
                        'is_active': bool(row['is_active']),
                        'created_at': row['created_at'],
                        'last_verification': row['last_verification']
                    })

        except Exception as e:
            logger.error(f"Erro ao exportar dados de usuÃ¡rios: {e}")
            return []

        return users_data

    def export_user_states(self) -> list:
        """Exporta estados de usuÃ¡rios"""
        states_data = []

        try:
            with self.get_db_connection() as conn:
                cursor = conn.execute("""
                    SELECT
                        user_id,
                        has_interacted,
                        last_interaction
                    FROM user_states
                    ORDER BY user_id
                """)

                for row in cursor.fetchall():
                    states_data.append({
                        'user_id': row['user_id'],
                        'has_interacted': bool(row['has_interacted']),
                        'last_interaction': row['last_interaction']
                    })

        except Exception as e:
            logger.warning(f"Tabela user_states nÃ£o encontrada ou erro: {e}")
            return []

        return states_data

    def export_user_rules(self) -> list:
        """Exporta dados de regras aceitas"""
        rules_data = []

        try:
            with self.get_db_connection() as conn:
                cursor = conn.execute("""
                    SELECT
                        user_id,
                        username,
                        joined_at,
                        rules_accepted,
                        rules_accepted_at,
                        expires_at,
                        status
                    FROM user_rules
                    ORDER BY user_id
                """)

                for row in cursor.fetchall():
                    rules_data.append({
                        'user_id': row['user_id'],
                        'username': row['username'],
                        'joined_at': row['joined_at'],
                        'rules_accepted': bool(row['rules_accepted']),
                        'rules_accepted_at': row['rules_accepted_at'],
                        'expires_at': row['expires_at'],
                        'status': row['status']
                    })

        except Exception as e:
            logger.warning(f"Tabela user_rules nÃ£o encontrada ou erro: {e}")
            return []

        return rules_data

    def export_migration_history(self) -> list:
        """Exporta histÃ³rico de migrations aplicadas"""
        migrations_data = []

        try:
            with self.get_db_connection() as conn:
                cursor = conn.execute("""
                    SELECT
                        version,
                        filename,
                        applied_at,
                        checksum
                    FROM schema_migrations
                    ORDER BY version
                """)

                for row in cursor.fetchall():
                    migrations_data.append({
                        'version': row['version'],
                        'filename': row['filename'],
                        'applied_at': row['applied_at'],
                        'checksum': row['checksum']
                    })

        except Exception as e:
            logger.warning(f"Tabela schema_migrations nÃ£o encontrada ou erro: {e}")
            return []

        return migrations_data

    def export_support_tickets_summary(self) -> list:
        """Exporta resumo dos tickets de suporte (sem dados sensÃ­veis)"""
        tickets_data = []

        try:
            with self.get_db_connection() as conn:
                cursor = conn.execute("""
                    SELECT
                        id,
                        user_id,
                        username,
                        category,
                        affected_game,
                        urgency_level,
                        status,
                        created_at,
                        resolved_at
                    FROM support_tickets
                    ORDER BY id
                """)

                for row in cursor.fetchall():
                    tickets_data.append({
                        'id': row['id'],
                        'user_id': row['user_id'],
                        'username': row['username'],
                        'category': row['category'],
                        'affected_game': row['affected_game'],
                        'urgency_level': row['urgency_level'],
                        'status': row['status'],
                        'created_at': row['created_at'],
                        'resolved_at': row['resolved_at']
                    })

        except Exception as e:
            logger.warning(f"Tabela support_tickets nÃ£o encontrada ou erro: {e}")
            return []

        return tickets_data

    def create_critical_export(self) -> dict:
        """Cria export completo dos dados crÃ­ticos"""
        timestamp = datetime.now()

        logger.info("ğŸ“¦ Exportando dados crÃ­ticos...")

        # Exporta cada tipo de dado
        users_data = self.export_users_critical_data()
        states_data = self.export_user_states()
        rules_data = self.export_user_rules()
        migrations_data = self.export_migration_history()
        tickets_summary = self.export_support_tickets_summary()

        # Monta export completo
        export_data = {
            'export_info': {
                'timestamp': timestamp.isoformat(),
                'database_file': self.database_path,
                'export_version': '1.0',
                'description': 'Export de dados crÃ­ticos do OnCabito Bot'
            },
            'statistics': {
                'total_users': len(users_data),
                'users_with_cpf': len([u for u in users_data if u.get('cpf')]),
                'active_users': len([u for u in users_data if u.get('is_active')]),
                'user_states': len(states_data),
                'user_rules': len(rules_data),
                'applied_migrations': len(migrations_data),
                'support_tickets': len(tickets_summary)
            },
            'data': {
                'users': users_data,
                'user_states': states_data,
                'user_rules': rules_data,
                'schema_migrations': migrations_data,
                'support_tickets_summary': tickets_summary
            }
        }

        # Salva arquivo
        filename = f"critical_data_{timestamp.strftime('%Y%m%d_%H%M%S')}.json"
        filepath = self.export_dir / filename

        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False, default=str)

            file_size = filepath.stat().st_size
            logger.info(f"âœ… Export salvo: {filepath} ({file_size:,} bytes)")

            # Limpa exports antigos (mantÃ©m Ãºltimos 30 dias)
            self.cleanup_old_exports()

            return {
                'success': True,
                'filepath': str(filepath),
                'file_size': file_size,
                'statistics': export_data['statistics']
            }

        except Exception as e:
            logger.error(f"âŒ Erro ao salvar export: {e}")
            return {
                'success': False,
                'error': str(e)
            }

    def cleanup_old_exports(self):
        """Remove exports antigos (> 30 dias)"""
        try:
            import time
            cutoff_time = time.time() - (30 * 24 * 60 * 60)  # 30 dias

            removed_count = 0
            for file_path in self.export_dir.glob("critical_data_*.json"):
                if file_path.stat().st_mtime < cutoff_time:
                    file_path.unlink()
                    removed_count += 1

            if removed_count > 0:
                logger.info(f"ğŸ§¹ Removidos {removed_count} export(s) antigo(s)")

        except Exception as e:
            logger.warning(f"Erro na limpeza de exports antigos: {e}")

    def list_exports(self) -> list:
        """Lista exports disponÃ­veis"""
        exports = []

        for file_path in sorted(self.export_dir.glob("critical_data_*.json")):
            try:
                stat = file_path.stat()
                exports.append({
                    'filename': file_path.name,
                    'filepath': str(file_path),
                    'size': stat.st_size,
                    'created': datetime.fromtimestamp(stat.st_mtime).isoformat()
                })
            except Exception as e:
                logger.warning(f"Erro ao ler arquivo {file_path}: {e}")

        return exports

def main():
    """FunÃ§Ã£o principal"""

    # Verifica se o banco existe
    if not os.path.exists(DATABASE_FILE):
        logger.error(f"âŒ Banco de dados nÃ£o encontrado: {DATABASE_FILE}")
        sys.exit(1)

    # Executa export
    exporter = CriticalDataExporter(DATABASE_FILE)
    result = exporter.create_critical_export()

    # Mostra resultado
    print(f"\nğŸ“¦ EXPORT DE DADOS CRÃTICOS")
    print(f"===========================")
    print(f"ğŸ•’ HorÃ¡rio: {datetime.now().strftime('%d/%m/%Y Ã s %H:%M:%S')}")

    if result['success']:
        print(f"âœ… Status: SUCESSO")
        print(f"ğŸ“ Arquivo: {result['filepath']}")
        print(f"ğŸ“Š Tamanho: {result['file_size']:,} bytes")

        stats = result['statistics']
        print(f"\nğŸ“ˆ ESTATÃSTICAS:")
        print(f"ğŸ‘¥ Total de usuÃ¡rios: {stats['total_users']}")
        print(f"ğŸ”— UsuÃ¡rios com CPF: {stats['users_with_cpf']}")
        print(f"âœ… UsuÃ¡rios ativos: {stats['active_users']}")
        print(f"ğŸ“Š Estados de usuÃ¡rio: {stats['user_states']}")
        print(f"ğŸ“‹ Regras aceitas: {stats['user_rules']}")
        print(f"ğŸ”„ Migrations aplicadas: {stats['applied_migrations']}")
        print(f"ğŸ« Tickets de suporte: {stats['support_tickets']}")

        # Lista exports disponÃ­veis
        exports = exporter.list_exports()
        print(f"\nğŸ“ EXPORTS DISPONÃVEIS: {len(exports)}")
        for export in exports[-3:]:  # Mostra Ãºltimos 3
            created = datetime.fromisoformat(export['created']).strftime('%d/%m/%Y %H:%M')
            print(f"   â€¢ {export['filename']} ({export['size']:,} bytes) - {created}")

        print(f"\nğŸ“ Logs: logs/")
        print(f"ğŸ“‚ DiretÃ³rio: backups/critical_data/")

        sys.exit(0)
    else:
        print(f"âŒ Status: ERRO")
        print(f"ğŸ’¥ Erro: {result['error']}")
        sys.exit(1)

if __name__ == "__main__":
    main()